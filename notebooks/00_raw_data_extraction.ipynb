{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c059ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9633bcc7",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8919b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available splits: ['train', 'validation', 'test']\n"
     ]
    }
   ],
   "source": [
    "# Load the CLINIC oos dataset from Hugging Face\n",
    "dataset = load_dataset(\"clinc/clinc_oos\", \"plus\")\n",
    "print(\"Available splits:\", list(dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28c6e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'intent'],\n",
      "    num_rows: 15250\n",
      "})\n",
      "Features: {'text': Value('string'), 'intent': ClassLabel(names=['restaurant_reviews', 'nutrition_info', 'account_blocked', 'oil_change_how', 'time', 'weather', 'redeem_rewards', 'interest_rate', 'gas_type', 'accept_reservations', 'smart_home', 'user_name', 'report_lost_card', 'repeat', 'whisper_mode', 'what_are_your_hobbies', 'order', 'jump_start', 'schedule_meeting', 'meeting_schedule', 'freeze_account', 'what_song', 'meaning_of_life', 'restaurant_reservation', 'traffic', 'make_call', 'text', 'bill_balance', 'improve_credit_score', 'change_language', 'no', 'measurement_conversion', 'timer', 'flip_coin', 'do_you_have_pets', 'balance', 'tell_joke', 'last_maintenance', 'exchange_rate', 'uber', 'car_rental', 'credit_limit', 'oos', 'shopping_list', 'expiration_date', 'routing', 'meal_suggestion', 'tire_change', 'todo_list', 'card_declined', 'rewards_balance', 'change_accent', 'vaccines', 'reminder_update', 'food_last', 'change_ai_name', 'bill_due', 'who_do_you_work_for', 'share_location', 'international_visa', 'calendar', 'translate', 'carry_on', 'book_flight', 'insurance_change', 'todo_list_update', 'timezone', 'cancel_reservation', 'transactions', 'credit_score', 'report_fraud', 'spending_history', 'directions', 'spelling', 'insurance', 'what_is_your_name', 'reminder', 'where_are_you_from', 'distance', 'payday', 'flight_status', 'find_phone', 'greeting', 'alarm', 'order_status', 'confirm_reservation', 'cook_time', 'damaged_card', 'reset_settings', 'pin_change', 'replacement_card_duration', 'new_card', 'roll_dice', 'income', 'taxes', 'date', 'who_made_you', 'pto_request', 'tire_pressure', 'how_old_are_you', 'rollover_401k', 'pto_request_status', 'how_busy', 'application_status', 'recipe', 'calendar_update', 'play_music', 'yes', 'direct_deposit', 'credit_limit_change', 'gas', 'pay_bill', 'ingredients_list', 'lost_luggage', 'goodbye', 'what_can_i_ask_you', 'book_hotel', 'are_you_a_bot', 'next_song', 'change_speed', 'plug_type', 'maybe', 'w2', 'oil_change_when', 'thank_you', 'shopping_list_update', 'pto_balance', 'order_checks', 'travel_alert', 'fun_fact', 'sync_device', 'schedule_maintenance', 'apr', 'transfer', 'ingredient_substitution', 'calories', 'current_location', 'international_fees', 'calculator', 'definition', 'next_holiday', 'update_playlist', 'mpg', 'min_payment', 'change_user_name', 'restaurant_suggestion', 'travel_notification', 'cancel', 'pto_used', 'travel_suggestion', 'change_volume'])}\n",
      "First example: {'text': 'what expression would i use to say i love you if i were an italian', 'intent': 61}\n"
     ]
    }
   ],
   "source": [
    "# Display basic info about the dataset\n",
    "print(dataset[\"train\"])\n",
    "print(\"Features:\", dataset[\"train\"].features)\n",
    "print(\"First example:\", dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e80f5",
   "metadata": {},
   "source": [
    "## Define Intent Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d28321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our mapping from the source dataset's integer labels to our new intent names.\n",
    "\n",
    "# Our intent : [list of clinic_oos integer labels]\n",
    "INTENT_MAPPING = {\n",
    "    \"greeting\": [82],\t\t\t  # greeting\n",
    "    \"positive_reply\": [107, 124], # yes, thank_you\n",
    "    \"negative_reply\": [30],       # no\n",
    "    \"bye\": [114],                 # goodbye\n",
    "    \"oos\": [42]                   # oos\n",
    "}\n",
    "\n",
    "# To make lookup faster, we'll reverse the mapping\n",
    "# {source_label: our_intent}\n",
    "LABEL_TO_INTENT = {label: intent for intent, labels in INTENT_MAPPING.items() for label in labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb73c8",
   "metadata": {},
   "source": [
    "## Extract and Remap Data from All Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0560a41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split: 'train'...\n",
      "Processing split: 'validation'...\n",
      "Processing split: 'test'...\n",
      "\n",
      "Extraction complete. Total remapped entries found: 2100\n"
     ]
    }
   ],
   "source": [
    "# We'll iterate through every split (train, validation, test) and extract the\n",
    "# entries that match our required intents.\n",
    "\n",
    "all_entries = []\n",
    "\n",
    "for split_name in dataset.keys():\n",
    "    print(f\"Processing split: '{split_name}'...\")\n",
    "    current_split = dataset[split_name]\n",
    "    \n",
    "    for entry in current_split:\n",
    "        source_label = entry['intent']\n",
    "        \n",
    "        # Check if the entry's intent is one we need to map\n",
    "        if source_label in LABEL_TO_INTENT:\n",
    "            remapped_intent = LABEL_TO_INTENT[source_label]\n",
    "            all_entries.append({\n",
    "                \"text\": entry['text'],\n",
    "                \"intent\": remapped_intent\n",
    "            })\n",
    "\n",
    "print(f\"\\nExtraction complete. Total remapped entries found: {len(all_entries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e304e97",
   "metadata": {},
   "source": [
    "## Visualize Entry Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea2fc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Number of Entries Gathered per Intent ---\n",
      "intent\n",
      "oos               1350\n",
      "positive_reply     300\n",
      "negative_reply     150\n",
      "bye                150\n",
      "greeting           150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Before saving, let's create a DataFrame and visualize the number of\n",
    "# entries we've gathered for each of our new intents.\n",
    "\n",
    "df = pd.DataFrame(all_entries)\n",
    "intent_counts = df['intent'].value_counts()\n",
    "\n",
    "print(\"--- Number of Entries Gathered per Intent ---\")\n",
    "print(intent_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d965b42",
   "metadata": {},
   "source": [
    "## Sampling for class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c59fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sampled Dataset Info ---\n",
      "Total entries in sampled data: 750\n",
      "Sampled counts per intent:\n",
      "intent\n",
      "bye               150\n",
      "greeting          150\n",
      "negative_reply    150\n",
      "oos               150\n",
      "positive_reply    150\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aceto\\AppData\\Local\\Temp\\ipykernel_19340\\2151548401.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=min(len(x), N_SAMPLES), random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# --- Sampling Logic ---\n",
    "# We want to sample 150 entries per intent.\n",
    "N_SAMPLES = 150\n",
    "\n",
    "# We group by 'intent' and then apply a sampling function to each group.\n",
    "# The lambda function is key to handling intents with fewer than N_SAMPLES entries.\n",
    "# It takes the minimum of the group size and our desired sample size.\n",
    "# `random_state` ensures the sampling is reproducible.\n",
    "sampled_df = (\n",
    "    df.groupby('intent', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=min(len(x), N_SAMPLES), random_state=42))\n",
    ")\n",
    "\n",
    "print(\"\\n--- Sampled Dataset Info ---\")\n",
    "print(f\"Total entries in sampled data: {len(sampled_df)}\")\n",
    "print(\"Sampled counts per intent:\")\n",
    "print(sampled_df['intent'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f9d67",
   "metadata": {},
   "source": [
    "## Save Remapped Intents to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deddc362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving files to 'c:\\Users\\aceto\\Documents\\GitHub\\schedulebot-plus\\data\\raw\\intents' directory...\n",
      " -> Saved 'bye.csv' with 150 rows.\n",
      " -> Saved 'greeting.csv' with 150 rows.\n",
      " -> Saved 'negative_reply.csv' with 150 rows.\n",
      " -> Saved 'oos.csv' with 150 rows.\n",
      " -> Saved 'positive_reply.csv' with 150 rows.\n",
      "\n",
      "✅ All files have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Finally, we'll save each intent group to its own CSV file in the specified directory.\n",
    "project_root = Path().cwd().parent\n",
    "output_dir = str(project_root / \"data\" / \"raw\" / \"intents\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nSaving files to '{output_dir}' directory...\")\n",
    "\n",
    "# Group the DataFrame by our new intent names\n",
    "for intent_name, group_df in sampled_df.groupby('intent'):\n",
    "    file_path = os.path.join(output_dir, f\"{intent_name}.csv\")\n",
    "    \n",
    "    # Select only the 'text' and 'intent' columns for saving\n",
    "    save_df = group_df[['text', 'intent']]\n",
    "    \n",
    "    save_df.to_csv(file_path, index=False)\n",
    "    print(f\" -> Saved '{intent_name}.csv' with {len(save_df)} rows.\")\n",
    "\n",
    "print(\"\\n✅ All files have been saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schedulebot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
